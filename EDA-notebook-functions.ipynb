{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a0003ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_grocery_data(data):\n",
    "    # Getting the column names\n",
    "    column_names = data.columns.tolist()\n",
    "\n",
    "    # Rename existing columns\n",
    "    rename_mapping = {\n",
    "        'Day': 'date',\n",
    "        'Category level 0': 'category_level_0',\n",
    "        'Category level 1': 'category_level_1',\n",
    "        'Category level 2': 'category_level_2',\n",
    "        'Unique SKUs Listed': 'SKUs_listed[Unique]',\n",
    "        'Unique SKUs Sold': 'SKUs_sold',\n",
    "        '# of sold SKU items': 'SKUs_items_sold',\n",
    "        'Sales value before discount (EUR)': 'sale_price_without_discount(euros)',\n",
    "        'User Discount Value (EUR)': 'user_discounts(euros)',\n",
    "        'Total COGS for Sold items (net VAT) (EUR)': 'sold_items_total_cogs(euro)',\n",
    "        'Waste, # of items': 'items_wasted'\n",
    "    }\n",
    "\n",
    "    data.rename(columns=rename_mapping, inplace=True)\n",
    "\n",
    "    # Reordering the columns\n",
    "    new_column_order = ['date', 'category_level_0', 'category_level_1', 'category_level_2',\n",
    "                        'SKUs_listed[Unique]', 'SKUs_sold', 'SKUs_items_sold', 'sale_price_without_discount(euros)',\n",
    "                        'user_discounts(euros)', 'sold_items_total_cogs(euro)', 'items_wasted']\n",
    "\n",
    "    data = data[new_column_order]\n",
    "\n",
    "    # Sorting the dataframe\n",
    "    sort_columns = ['date', 'category_level_0', 'category_level_1', 'category_level_2']\n",
    "    data = data.sort_values(by=sort_columns)\n",
    "\n",
    "    # Resetting index\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab244ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_data_info(data):\n",
    "    # Checking for missing values\n",
    "    missing_values = data.isnull().sum()\n",
    "    print(\"Missing values:\")\n",
    "    print(missing_values)\n",
    "    print(\"\\nNumber of columns with missing values:\", missing_values[missing_values > 0].count())\n",
    "\n",
    "    # Checking data types\n",
    "    data_types = data.dtypes\n",
    "    print(\"\\nData types of columns:\")\n",
    "    print(data_types)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d7cbfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_zero_values(data):\n",
    "    # Selecting columns for analysis\n",
    "    columns_to_check = [\n",
    "        'SKUs_listed[Unique]',\n",
    "        'SKUs_sold',\n",
    "        'SKUs_items_sold',\n",
    "        'sale_price_without_discount(euros)',\n",
    "        'user_discounts(euros)',\n",
    "        'sold_items_total_cogs(euro)'\n",
    "    ]\n",
    "\n",
    "    # Filtering rows with all zero values\n",
    "    zero_values_instances = data[data[columns_to_check].eq(0).all(axis=1)].reset_index(drop=True)\n",
    "\n",
    "    # Countplots for category levels\n",
    "    for level in ['category_level_0', 'category_level_1', 'category_level_2']:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.countplot(x=level, data=zero_values_instances, palette='viridis')\n",
    "        plt.title(f'Zero Values Instances by {level}')\n",
    "        plt.xlabel(level)\n",
    "        plt.ylabel('Count')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14835726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_checks(grocery_sales_inventory_data):\n",
    "    # Check 1\n",
    "    check_1_instances = grocery_sales_inventory_data[(grocery_sales_inventory_data['SKUs_listed[Unique]'] == 0) \n",
    "                                                     & (grocery_sales_inventory_data['SKUs_sold'] > 0) \n",
    "                                                     & (grocery_sales_inventory_data['SKUs_items_sold'] > 0)]\n",
    "    check_1_count = len(check_1_instances)\n",
    "    \n",
    "    # Check 2\n",
    "    check_2_instances = grocery_sales_inventory_data[(grocery_sales_inventory_data['SKUs_sold'] == 0) \n",
    "                                            & (grocery_sales_inventory_data['SKUs_items_sold'] == 0)\n",
    "                                            & ((grocery_sales_inventory_data['sale_price_without_discount(euros)'] > 0)|\n",
    "                                              (grocery_sales_inventory_data['user_discounts(euros)'] > 0) |\n",
    "                                              (grocery_sales_inventory_data['sold_items_total_cogs(euro)'] > 0))]\n",
    "    check_2_count = len(check_2_instances)\n",
    "    \n",
    "    # Check 3\n",
    "    check_3_instances = grocery_sales_inventory_data[(grocery_sales_inventory_data['SKUs_items_sold'] == 0) \n",
    "                                                     & (grocery_sales_inventory_data['items_wasted'] > 0)]\n",
    "    check_3_count = len(check_3_instances)\n",
    "    \n",
    "    # Check 4\n",
    "    check_4_instances = grocery_sales_inventory_data[(grocery_sales_inventory_data['SKUs_listed[Unique]'] == 0) \n",
    "                                                     & (grocery_sales_inventory_data['items_wasted'] > 0)]\n",
    "    check_4_count = len(check_4_instances)\n",
    "    \n",
    "    result = {\n",
    "        'Check 1': {'count': check_1_count, 'comment': \"Instances where SKUs_listed[Unique] is zero with non-zero SKUs_sold and SKUs_items_sold are:\"},\n",
    "        'Check 2': {'count': check_2_count, 'comment': \"Instances where sale_price_without_discount, user_discounts, and sold_items_total_cogs are non-zero when SKUs_sold and SKUs_items_sold are zero are:\"},\n",
    "        'Check 3': {'count': check_3_count, 'comment': \"Instances where wasted items are non-zero when SKUs_items_sold is zero are:\"},\n",
    "        'Check 4': {'count': check_4_count, 'comment': \"Instances where wasted items are non-zero when SKUs_listed[Unique] is zero are:\"}\n",
    "    }\n",
    "    \n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53fd981b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grouped_data_with_zero_sales_info(data):\n",
    "    # Grouping by the categories and aggregate metrics\n",
    "    grouped_data = data.groupby(['category_level_0', 'category_level_1', 'category_level_2']).agg({\n",
    "        'SKUs_listed[Unique]': 'sum',\n",
    "        'SKUs_sold': 'sum',\n",
    "        'SKUs_items_sold': 'sum',\n",
    "        'sale_price_without_discount(euros)': 'sum',\n",
    "        'user_discounts(euros)': 'sum',\n",
    "        'sold_items_total_cogs(euro)': 'sum',\n",
    "        'items_wasted': 'sum'\n",
    "    }).reset_index()\n",
    "\n",
    "    # Filtering out instances where sale_price_without_discount(euros) grouped is zero\n",
    "    filtered_data = grouped_data[\n",
    "        (grouped_data['sale_price_without_discount(euros)'] == 0) &\n",
    "        (grouped_data['SKUs_sold'] != 0)\n",
    "    ]\n",
    "\n",
    "    # Resetting the index\n",
    "    filtered_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Displaying the size of both dataframes\n",
    "    print(\"Total Unique Categories:\", grouped_data.shape[0])\n",
    "    print(\"Categories with Zero Sales Information:\", filtered_data.shape[0])\n",
    "\n",
    "    return grouped_data, filtered_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb8abcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def applying_feature_engineering(grocery_sales_inventory_data):\n",
    "    # Assumption 1: Fill missing values in 'sale_price_without_discount(euros)'\n",
    "    mask = (grocery_sales_inventory_data['sale_price_without_discount(euros)'] == 0)\n",
    "    grocery_sales_inventory_data['sale_price_without_discount(euros)'] = np.where(mask, \n",
    "                                            grocery_sales_inventory_data['sold_items_total_cogs(euro)'] +\n",
    "                                            grocery_sales_inventory_data['user_discounts(euros)'], \n",
    "                                            grocery_sales_inventory_data['sale_price_without_discount(euros)'])\n",
    "\n",
    "    # Assumption 2: Replace 'SKUs_sold' with 'SKUs_listed' where 'SKUs_listed' is zero\n",
    "    grocery_sales_inventory_data.loc[(grocery_sales_inventory_data['SKUs_listed[Unique]'] == 0) & \n",
    "                                      (grocery_sales_inventory_data['SKUs_sold'] != 0) &\n",
    "                                      (grocery_sales_inventory_data['SKUs_items_sold'] != 0),\n",
    "                                     'SKUs_listed[Unique]'] = grocery_sales_inventory_data['SKUs_sold']\n",
    "\n",
    "    # Introducing new columns: sale_price_with_discount(euros) and net_revenue\n",
    "    grocery_sales_inventory_data['sale_price_with_discount(euros)'] = \\\n",
    "        grocery_sales_inventory_data['sale_price_without_discount(euros)'] - grocery_sales_inventory_data['user_discounts(euros)']\n",
    "\n",
    "    grocery_sales_inventory_data['net_revenue'] = \\\n",
    "        grocery_sales_inventory_data['sale_price_with_discount(euros)'] - grocery_sales_inventory_data['sold_items_total_cogs(euro)']\n",
    "\n",
    "    # Extracting weekday and month from the \"date\" column\n",
    "    grocery_sales_inventory_data['weekday'] = pd.to_datetime(grocery_sales_inventory_data['date']).dt.strftime('%a')\n",
    "    grocery_sales_inventory_data['month'] = pd.to_datetime(grocery_sales_inventory_data['date']).dt.strftime('%b')\n",
    "\n",
    "    # Reordering the columns\n",
    "    new_column_order = ['date', 'month', 'weekday', 'category_level_0', 'category_level_1', 'category_level_2',\n",
    "                        'SKUs_listed[Unique]', 'SKUs_sold', 'SKUs_items_sold', 'sale_price_without_discount(euros)',\n",
    "                        'user_discounts(euros)', 'sale_price_with_discount(euros)', 'sold_items_total_cogs(euro)',\n",
    "                        'net_revenue', 'items_wasted']\n",
    "\n",
    "    grocery_sales_inventory_data = grocery_sales_inventory_data[new_column_order]\n",
    "\n",
    "    # Sorting the dataframe\n",
    "    sort_columns = ['date', 'category_level_0', 'category_level_1', 'category_level_2', 'net_revenue']\n",
    "    grocery_sales_inventory_data = grocery_sales_inventory_data.sort_values(by=sort_columns)\n",
    "\n",
    "    # Resetting index\n",
    "    grocery_sales_inventory_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # List of columns to check for zero values\n",
    "    columns_to_check = ['SKUs_listed[Unique]', 'SKUs_sold', 'SKUs_items_sold', \n",
    "                         'sale_price_without_discount(euros)', 'user_discounts(euros)', \n",
    "                         'sale_price_with_discount(euros)', 'sold_items_total_cogs(euro)', \n",
    "                         'net_revenue', 'items_wasted']\n",
    "\n",
    "    # Drop rows where specified columns have zero values\n",
    "    grocery_sales_inventory_data_final = grocery_sales_inventory_data[grocery_sales_inventory_data[columns_to_check].ne(0).any(axis=1)]\n",
    "\n",
    "    # Reset the index\n",
    "    grocery_sales_inventory_data_final.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return grocery_sales_inventory_data_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da6288ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "\n",
    "def convert_seaborn_palette(seaborn_palette):\n",
    "    return [f'rgb({int(r * 255)},{int(g * 255)},{int(b * 255)})' for r, g, b in seaborn_palette]\n",
    "\n",
    "def plot_overall_monthly_aggregated_metrics(df):\n",
    "    # Define a specific sequence of months\n",
    "    month_order = ['Apr', 'May', 'Jun']\n",
    "    \n",
    "    columns_to_aggregate = ['sale_price_without_discount(euros)', 'user_discounts(euros)', 'net_revenue', 'SKUs_items_sold','items_wasted']\n",
    "\n",
    "    # Group by month and aggregate the specified columns\n",
    "    agg_data_monthly = df.groupby('month')[columns_to_aggregate].sum().reset_index()\n",
    "    \n",
    "    # Sort the aggregated data based on the custom month order\n",
    "    agg_data_monthly['month'] = pd.Categorical(agg_data_monthly['month'], categories=month_order, ordered=True)\n",
    "    agg_data_monthly = agg_data_monthly.sort_values('month')\n",
    "\n",
    "    # Define a color palette with higher tones of green\n",
    "    green_palette = sns.color_palette(\"dark:#38A169\", len(columns_to_aggregate))\n",
    "    plotly_palette = convert_seaborn_palette(green_palette)\n",
    "\n",
    "    # Create a line plot for each metric\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for i, column in enumerate(columns_to_aggregate):\n",
    "        fig.add_trace(go.Scatter(x=agg_data_monthly['month'], y=agg_data_monthly[column],\n",
    "                                 mode='lines+markers', name=column, line=dict(color=plotly_palette[i])))\n",
    "\n",
    "    fig.update_layout(title='Overall Monthly Aggregated Metrics',\n",
    "                      xaxis_title='Month',\n",
    "                      yaxis_title='Values')\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e298f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_seaborn_palette(seaborn_palette):\n",
    "    return [f'rgb({int(r * 255)},{int(g * 255)},{int(b * 255)})' for r, g, b in seaborn_palette]\n",
    "\n",
    "def plot_category_level_0_monthly_aggregated_metrics(df):\n",
    "    # Define a specific sequence of months\n",
    "    month_order = ['Apr', 'May', 'Jun']\n",
    "    \n",
    "    columns_to_aggregate = ['sale_price_without_discount(euros)', 'user_discounts(euros)', 'net_revenue', 'SKUs_items_sold', 'items_wasted']\n",
    "\n",
    "    # Group by category_level_0, month, and aggregate the specified columns\n",
    "    agg_data_category_month = df.groupby(['category_level_0', 'month'])[columns_to_aggregate].sum().reset_index()\n",
    "    \n",
    "    # Sort the aggregated data based on the custom month order\n",
    "    agg_data_category_month['month'] = pd.Categorical(agg_data_category_month['month'], categories=month_order, ordered=True)\n",
    "    agg_data_category_month = agg_data_category_month.sort_values(['category_level_0', 'month'])\n",
    "\n",
    "    # Define a color palette with higher tones of green\n",
    "    green_palette = sns.color_palette(\"dark:#38A169\", len(columns_to_aggregate))\n",
    "    plotly_palette = convert_seaborn_palette(green_palette)\n",
    "\n",
    "    for column in columns_to_aggregate:\n",
    "        # Create line plots for each category_level_0\n",
    "        fig = go.Figure()\n",
    "        for i, category in enumerate(agg_data_category_month['category_level_0'].unique()):\n",
    "            subset = agg_data_category_month[agg_data_category_month['category_level_0'] == category]\n",
    "            fig.add_trace(go.Scatter(x=subset['month'], y=subset[column],\n",
    "                                     mode='lines+markers', name=f'{category} - {column}', line=dict(color=plotly_palette[i])))\n",
    "        fig.update_layout(title=f'Category Level 0 Monthly Aggregated Metrics - {column}',\n",
    "                          xaxis_title='Month',\n",
    "                          yaxis_title='Values')\n",
    "        fig.show()\n",
    "\n",
    "        # Print calculated insights for each category_level_0\n",
    "        for category in agg_data_category_month['category_level_0'].unique():\n",
    "            subset_apr = agg_data_category_month[(agg_data_category_month['category_level_0'] == category) & (agg_data_category_month['month'] == 'Apr')]\n",
    "            subset_may = agg_data_category_month[(agg_data_category_month['category_level_0'] == category) & (agg_data_category_month['month'] == 'May')]\n",
    "            subset_jun = agg_data_category_month[(agg_data_category_month['category_level_0'] == category) & (agg_data_category_month['month'] == 'Jun')]\n",
    "            \n",
    "            if not subset_apr.empty and not subset_may.empty and not subset_jun.empty:\n",
    "                print(f\"** Insights for Category: {category} - {column} **\")\n",
    "                diff_apr_may = subset_may[column].values[0] - subset_apr[column].values[0]\n",
    "                diff_may_jun = subset_jun[column].values[0] - subset_may[column].values[0]\n",
    "\n",
    "                print(f\"Values increased from Apr to May by {abs(diff_apr_may):,.2f}.\" if diff_apr_may > 0 else\n",
    "                      f\"Values decreased from Apr to May by {abs(diff_apr_may):,.2f}.\" if diff_apr_may < 0 else\n",
    "                      \"Values remained constant from Apr to May.\")\n",
    "\n",
    "                print(f\"Values increased from May to Jun by {abs(diff_may_jun):,.2f}.\" if diff_may_jun > 0 else\n",
    "                      f\"Values decreased from May to Jun by {abs(diff_may_jun):,.2f}.\" if diff_may_jun < 0 else\n",
    "                      \"Values remained constant from May to Jun.\")\n",
    "                print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00bf81c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def aggregate_and_display_category_level(df):\n",
    "    \n",
    "    category_level = ['category_level_0', 'category_level_1', 'category_level_2']\n",
    "    \n",
    "    columns_to_aggregate = ['sale_price_without_discount(euros)', 'user_discounts(euros)', 'net_revenue','SKUs_listed[Unique]' ,'SKUs_sold','SKUs_items_sold', 'items_wasted']\n",
    "    \n",
    "    # Group by category_level and aggregate the specified columns\n",
    "    agg_data_category_level = df.groupby(category_level)[columns_to_aggregate].sum().reset_index()\n",
    "\n",
    "    # Sort the aggregated data by 'net_revenue' in descending order\n",
    "    agg_data_category_level = agg_data_category_level.sort_values(by='net_revenue', ascending=False)\n",
    "\n",
    "    # Reindex the DataFrame\n",
    "    agg_data_category_level = agg_data_category_level.reset_index(drop=True)\n",
    "    \n",
    "    return agg_data_category_level\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f2bfc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_wastage_by_category(df, category_level, threshold=None):\n",
    "    # Group by category_level and calculate total wastage\n",
    "    wastage_by_category = df.groupby(category_level)['items_wasted'].sum().sort_values(ascending=False)\n",
    "\n",
    "    # Calculate percentage of total wastage\n",
    "    total_wastage = wastage_by_category.sum()\n",
    "    wastage_percentage = (wastage_by_category / total_wastage) * 100\n",
    "\n",
    "    # Apply threshold if specified\n",
    "    if threshold is not None:\n",
    "        filtered_wastage = wastage_percentage[wastage_by_category > threshold]\n",
    "    else:\n",
    "        filtered_wastage = wastage_percentage\n",
    "\n",
    "    # Reverse the color scale for lighter tones to represent lower percentages\n",
    "    colorscale = px.colors.sequential.Greens[::-1]\n",
    "\n",
    "    # Plot the bar chart\n",
    "    fig = px.bar(filtered_wastage, x=filtered_wastage.values, y=filtered_wastage.index, orientation='h',\n",
    "                 title=f'Categories with High Wastage [{category_level}] (Wastage > {threshold}%)' if threshold is not None else f'Categories with Wastage Percentage [{category_level}]',\n",
    "                 labels={'x': 'Percentage of Total Wastage', 'y': f'{category_level}'},\n",
    "                 color=filtered_wastage.values,\n",
    "                 color_continuous_scale=colorscale)\n",
    "    \n",
    "    # Show the plot\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe3b5a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_monthly_wastage_trends_by_category(df, category_level):\n",
    "    # Convert the 'date' column to datetime\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    # Create a copy of the DataFrame\n",
    "    monthly_wastage_trends = df.copy()\n",
    "    \n",
    "    # Extract month and year from the 'date' column\n",
    "    monthly_wastage_trends['month'] = monthly_wastage_trends['date'].dt.to_period(\"M\")\n",
    "    \n",
    "    # Group by category_level and month, and calculate total wastage\n",
    "    monthly_wastage_trends = monthly_wastage_trends.groupby([category_level, 'month'])['items_wasted'].sum().reset_index()\n",
    "\n",
    "    # Convert the 'month' column to string\n",
    "    monthly_wastage_trends['month'] = monthly_wastage_trends['month'].astype(str)\n",
    "\n",
    "    # Create a bar chart with trend lines\n",
    "    fig = px.bar(monthly_wastage_trends, x='month', y='items_wasted', color=category_level,\n",
    "                 title=f'Monthly Item Wastage Trends by {category_level}',\n",
    "                 labels={'items_wasted': 'Total Wasted Items'},\n",
    "                 hover_name=category_level, text='items_wasted',\n",
    "                 color_discrete_sequence=px.colors.sequential.Greens_r)  # Use reversed Greens color scale\n",
    "\n",
    "    # Add trend lines\n",
    "    fig.update_traces(\n",
    "        marker=dict(color=px.colors.sequential.Greens_r[-1]),\n",
    "        line=dict(color=px.colors.sequential.Greens_r[-1], width=3),\n",
    "        selector=dict(mode='lines')\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(showlegend=True, xaxis_title='Month', yaxis_title='Total Wasted Items', legend_title=category_level)\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "109ec320",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_daily_wastage_trends_by_category_level_0(df):\n",
    "    # Convert the 'date' column to datetime\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    # Group by category_level_0 and date, and calculate total wastage\n",
    "    daily_wastage_trends = df.groupby(['category_level_0', 'date'])['items_wasted'].sum().reset_index()\n",
    "\n",
    "    # Create a line chart with markers using dark green tones\n",
    "    fig = px.line(daily_wastage_trends, x='date', y='items_wasted', color='category_level_0', markers=True,\n",
    "                  title='Daily Item Wastage Trends by Category Level 0', labels={'items_wasted': 'Total Wasted Items'},\n",
    "                  color_discrete_sequence=px.colors.sequential.Greens_r)  # Use reversed Greens color scale\n",
    "\n",
    "    fig.update_traces(marker=dict(size=10, line=dict(color='white', width=2)),\n",
    "                      line=dict(width=3))\n",
    "\n",
    "    fig.update_layout(xaxis_title='Date', yaxis_title='Total Wasted Items', legend_title='Category Level 0',\n",
    "                      legend=dict(title=dict(text='Category Level 0'), orientation='h', yanchor='bottom', y=1.02, xanchor='right', x=1),\n",
    "                      plot_bgcolor='rgba(0,0,0,0)', paper_bgcolor='rgba(0,0,0,0)')\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88411938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_daily_wastage_trends_cat1_grocery_food(df):\n",
    "    # Filter data for Grocery Food at Category Level 0\n",
    "    filtered_data_cat2 = df[df['category_level_0'].isin(['Grocery Food'])]\n",
    "\n",
    "    # Group by Category Level 0, Category Level 1, and date, and calculate total wastage\n",
    "    daily_wastage_trends_cat2 = filtered_data_cat2.groupby(['category_level_0', 'category_level_1', 'date'])['items_wasted'].sum().reset_index()\n",
    "\n",
    "    # Create a line chart with markers using darker green tones\n",
    "    fig_cat2 = px.line(daily_wastage_trends_cat2, x='date', y='items_wasted', color='category_level_1', markers=True,\n",
    "                       title='Daily Item Wastage Trends by Category Level 1 within Grocery Food',\n",
    "                       labels={'items_wasted': 'Total Wasted Items'},\n",
    "                       color_discrete_sequence=px.colors.sequential.Greens_r)  # Use reversed Greens color scale\n",
    "\n",
    "    fig_cat2.update_traces(marker=dict(size=10, line=dict(width=2)))\n",
    "\n",
    "    fig_cat2.update_layout(xaxis_title='Date', yaxis_title='Total Wasted Items', legend_title='Category Level 1',\n",
    "                          legend=dict(title=dict(text='Category Level 1'), orientation='v', yanchor='top', xanchor='right', x=1.02, y=1),\n",
    "                          plot_bgcolor='rgba(0,0,0,0)', paper_bgcolor='rgba(0,0,0,0)')\n",
    "\n",
    "    fig_cat2.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cee2ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_daily_wastage_trends_fresh_food(df):\n",
    "    # Filter data for Fresh Food at Category Level 0\n",
    "    filtered_data_cat2 = df[df['category_level_0'].isin(['Fresh Food'])]\n",
    "\n",
    "    # Group by Category Level 0, Category Level 1, and date, and calculate total wastage\n",
    "    daily_wastage_trends_cat2 = filtered_data_cat2.groupby(['category_level_0', 'category_level_1', 'date'])['items_wasted'].sum().reset_index()\n",
    "\n",
    "    # Create a line chart with markers using darker green tones\n",
    "    fig_cat2 = px.line(daily_wastage_trends_cat2, x='date', y='items_wasted', color='category_level_1', markers=True,\n",
    "                       title='Daily Item Wastage Trends by Category Level 1 within Fresh Food',\n",
    "                       labels={'items_wasted': 'Total Wasted Items'},\n",
    "                       color_discrete_sequence=px.colors.sequential.Greens_r)  # Use reversed Greens color scale\n",
    "\n",
    "    fig_cat2.update_traces(marker=dict(size=10, line=dict(width=2)))\n",
    "\n",
    "    fig_cat2.update_layout(xaxis_title='Date', yaxis_title='Total Wasted Items', legend_title='Category Level 1',\n",
    "                          legend=dict(title=dict(text='Category Level 1'), orientation='v', yanchor='top', xanchor='right', x=1.02, y=1),\n",
    "                          plot_bgcolor='rgba(0,0,0,0)', paper_bgcolor='rgba(0,0,0,0)')\n",
    "\n",
    "    fig_cat2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72b2a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sales_trends(df):\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df = df.sort_values(by='date')\n",
    "\n",
    "    # Create a categorical column for month, weekday, and date with the correct sequence\n",
    "    month_order = ['Apr', 'May', 'Jun']\n",
    "    weekday_order = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "\n",
    "    df['month'] = pd.Categorical(df['month'], categories=month_order, ordered=True)\n",
    "    df['weekday'] = pd.Categorical(df['weekday'], categories=weekday_order, ordered=True)\n",
    "    df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "\n",
    "    # Group by month, weekday, and date and sum up the values\n",
    "    df_monthly = df.groupby('month').sum().reset_index()\n",
    "    df_weekly = df.groupby('weekday').sum().reset_index()\n",
    "    df_daily = df.groupby('date').sum().reset_index()\n",
    "\n",
    "    # Create a trend graph using plotly express\n",
    "    fig_monthly = px.line(df_monthly, x='month', y='sale_price_without_discount(euros)', title='Monthly Trend',\n",
    "                          labels={'sale_price_without_discount(euros)': 'Total Sales', 'month': 'Month'},\n",
    "                          line_shape='linear', color_discrete_sequence=px.colors.sequential.Greens_r)\n",
    "    fig_weekly = px.line(df_weekly, x='weekday', y='sale_price_without_discount(euros)', title='Weekday Trend',\n",
    "                         labels={'sale_price_without_discount(euros)': 'Total Sales', 'weekday': 'Weekday'},\n",
    "                         line_shape='linear', color_discrete_sequence=px.colors.sequential.Greens_r)\n",
    "    fig_daily = px.line(df_daily, x='date', y='sale_price_without_discount(euros)', title='Date-wise Trend',\n",
    "                        labels={'sale_price_without_discount(euros)': 'Total Sales', 'date': 'Date'},\n",
    "                        line_shape='linear', color_discrete_sequence=px.colors.sequential.Greens_r)\n",
    "\n",
    "    # Update y-axis formatting for better readability\n",
    "    fig_monthly.update_layout(yaxis=dict(tickformat=',.2f'))\n",
    "    fig_weekly.update_layout(yaxis=dict(tickformat=',.2f'))\n",
    "    fig_daily.update_layout(yaxis=dict(tickformat=',.2f'))\n",
    "\n",
    "    # Show hover information\n",
    "    fig_monthly.update_traces(mode='lines+markers', hovertemplate='%{x}<br>%{y:,.2f}')\n",
    "    fig_weekly.update_traces(mode='lines+markers', hovertemplate='%{x}<br>%{y:,.2f}')\n",
    "    fig_daily.update_traces(mode='lines+markers', hovertemplate='%{x}<br>%{y:,.2f}')\n",
    "\n",
    "    # Show the interactive plots\n",
    "    fig_monthly.show()\n",
    "    fig_weekly.show()\n",
    "    fig_daily.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "822098ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sku_listed_trends(df):\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df = df.sort_values(by='date')\n",
    "\n",
    "    # Create a categorical column for month, weekday, and date with the correct sequence\n",
    "    month_order = ['Apr', 'May', 'Jun']\n",
    "    weekday_order = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "\n",
    "    df['month'] = pd.Categorical(df['month'], categories=month_order, ordered=True)\n",
    "    df['weekday'] = pd.Categorical(df['weekday'], categories=weekday_order, ordered=True)\n",
    "    df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "\n",
    "    # Group by month, weekday, and date and get unique SKUs listed\n",
    "    df_monthly_sku = df.groupby('month')['SKUs_listed[Unique]'].nunique().reset_index()\n",
    "    df_weekly_sku = df.groupby('weekday')['SKUs_listed[Unique]'].nunique().reset_index()\n",
    "    df_daily_sku = df.groupby('date')['SKUs_listed[Unique]'].nunique().reset_index()\n",
    "\n",
    "    # Create a trend graph using plotly express\n",
    "    fig_monthly = px.line(df_monthly_sku, x='month', y='SKUs_listed[Unique]', title='Monthly SKU Listed Trends',\n",
    "                          labels={'SKUs_listed[Unique]': 'Unique SKUs Listed', 'month': 'Month'},\n",
    "                          line_shape='linear', color_discrete_sequence=px.colors.sequential.Greens_r)\n",
    "    fig_weekly = px.line(df_weekly_sku, x='weekday', y='SKUs_listed[Unique]', title='Weekly SKU Listed Trends',\n",
    "                         labels={'SKUs_listed[Unique]': 'Unique SKUs Listed', 'weekday': 'Weekday'},\n",
    "                         line_shape='linear', color_discrete_sequence=px.colors.sequential.Greens_r)\n",
    "    fig_daily = px.line(df_daily_sku, x='date', y='SKUs_listed[Unique]', title='Daily SKU Listed Trends',\n",
    "                        labels={'SKUs_listed[Unique]': 'Unique SKUs Listed', 'date': 'Date'},\n",
    "                        line_shape='linear', color_discrete_sequence=px.colors.sequential.Greens_r)\n",
    "\n",
    "    # Update y-axis formatting for better readability\n",
    "    fig_monthly.update_layout(yaxis=dict(tickformat=',.0f'))\n",
    "    fig_weekly.update_layout(yaxis=dict(tickformat=',.0f'))\n",
    "    fig_daily.update_layout(yaxis=dict(tickformat=',.0f'))\n",
    "\n",
    "    # Show hover information\n",
    "    fig_monthly.update_traces(mode='lines+markers', hovertemplate='%{x}<br>%{y:,.0f}')\n",
    "    fig_weekly.update_traces(mode='lines+markers', hovertemplate='%{x}<br>%{y:,.0f}')\n",
    "    fig_daily.update_traces(mode='lines+markers', hovertemplate='%{x}<br>%{y:,.0f}')\n",
    "\n",
    "    # Show the interactive plots\n",
    "    fig_monthly.show()\n",
    "    fig_weekly.show()\n",
    "    fig_daily.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a4bd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_category_level_1_trends(df):\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df = df.sort_values(by='date')\n",
    "\n",
    "    month_order = ['Apr', 'May', 'Jun']\n",
    "    weekday_order = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "\n",
    "    df['month'] = pd.Categorical(df['month'], categories=month_order, ordered=True)\n",
    "    df['weekday'] = pd.Categorical(df['weekday'], categories=weekday_order, ordered=True)\n",
    "    df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "\n",
    "    # Grouping by month, weekday, and date and sum up the values\n",
    "    df_monthly = df.groupby(['month', 'category_level_1']).sum().reset_index()\n",
    "    df_weekly = df.groupby(['weekday', 'category_level_1']).sum().reset_index()\n",
    "    df_daily = df.groupby(['date', 'category_level_1']).sum().reset_index()\n",
    "\n",
    "    # Reshape data to have months as columns and categories as rows\n",
    "    pivot_monthly = df_monthly.pivot(index='category_level_1', columns='month', values='sale_price_without_discount(euros)').fillna(0)\n",
    "\n",
    "    # Calculate the difference between June and April sales\n",
    "    sales_diff = pivot_monthly['Jun'] - pivot_monthly['Apr']\n",
    "\n",
    "    # Identify categories with a decrease or increase in sales\n",
    "    decrease_categories = sales_diff[sales_diff < 0].index.tolist()\n",
    "    increase_categories = sales_diff[sales_diff > 0].index.tolist()\n",
    "\n",
    "    # Print the results\n",
    "    print(\"\\nMonthly Trends at category level 1:\")\n",
    "    print(\"Decrease:\", decrease_categories)\n",
    "    print(\"Increase:\", increase_categories)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7be2199f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_high_margin_skus_category_level_1(df):\n",
    "    # Assuming your dataframe is named df\n",
    "    df['profit_margin'] = (df['sale_price_without_discount(euros)'] - df['sold_items_total_cogs(euro)'])  / df['sale_price_without_discount(euros)']\n",
    "\n",
    "    # Use .loc to avoid SettingWithCopyWarning\n",
    "    high_margin_skus = df.loc[df['profit_margin'] > 0.1].copy()\n",
    "\n",
    "    # Create an interactive boxplot with plotly.express\n",
    "    fig = px.box(high_margin_skus,\n",
    "                 x='category_level_1',\n",
    "                 y='profit_margin',\n",
    "                 color='category_level_1',\n",
    "                 title='SKUs with Higher Margins',\n",
    "                 labels={'profit_margin': 'Profit Margin', 'category_level_1': 'Category Level 1'},\n",
    "                 template='plotly_dark')\n",
    "\n",
    "    # Customize the box colors with dark green shades\n",
    "    dark_green_colorscale = px.colors.sequential.Greens[::-1]  # Reverse the Greens colorscale\n",
    "    color_indices = [i * (len(dark_green_colorscale) - 1) // len(high_margin_skus['category_level_1'].unique()) for i in range(len(high_margin_skus['category_level_1'].unique()))]\n",
    "\n",
    "    # Update boxpoints and pointpos to customize the marker position and color\n",
    "    for i, index in enumerate(color_indices):\n",
    "        # Ensure that pointpos falls within the acceptable range [-2, 2]\n",
    "        pointpos = max(-2, min(2, -index))\n",
    "        fig.data[i].update(boxpoints='all', pointpos=pointpos, jitter=0.3, marker=dict(color=dark_green_colorscale[index]))\n",
    "\n",
    "    # Set light green background\n",
    "    fig.update_layout(plot_bgcolor=px.colors.sequential.Greens[0])\n",
    "\n",
    "    # Show the interactive plot\n",
    "    fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd908dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_conversion_rate_by_category(df):\n",
    "    \"\"\"\n",
    "    Plots the conversion rate by category using Plotly Express box plot.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The input DataFrame containing the necessary columns.\n",
    "\n",
    "    Returns:\n",
    "    - fig (plotly.graph_objects.Figure): The Plotly figure object.\n",
    "    \"\"\"\n",
    "    # Calculate conversion rate\n",
    "    df['conversion_rate'] = df['SKUs_sold'] / df['SKUs_listed[Unique]']\n",
    "\n",
    "    # Filter outliers (conversion_rate between 0 and 1)\n",
    "    df = df[(df['conversion_rate'] >= 0) & (df['conversion_rate'] <= 1)]\n",
    "\n",
    "    # Plotly Express for interactive visualization\n",
    "    fig = px.box(df, x='conversion_rate', y='category_level_1', color='category_level_1',\n",
    "                 title='Conversion Rate by Category', labels={'conversion_rate': 'Conversion Rate'})\n",
    "    \n",
    "    # Set green color tones for background and boxplot\n",
    "    fig.update_layout(plot_bgcolor=px.colors.sequential.Greens[0])\n",
    "\n",
    "    # Customize axes titles\n",
    "    fig.update_layout(xaxis=dict(title='Conversion Rate'), yaxis=dict(title='Category Level 1'))\n",
    "\n",
    "    return fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8aa15013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def categorize_categories(df, high_net_margin_threshold=0.25, high_conversion_rate_threshold=0.40,\n",
    "                           low_net_margin_threshold=0.24, low_conversion_rate_threshold=0.39):\n",
    "    \"\"\"\n",
    "    Categorizes categories at category_level_1 based on net margin and conversion rate thresholds.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The input DataFrame containing the necessary columns.\n",
    "    - high_net_margin_threshold (float): Threshold for high net margin.\n",
    "    - high_conversion_rate_threshold (float): Threshold for high conversion rate.\n",
    "    - low_net_margin_threshold (float): Threshold for low net margin.\n",
    "    - low_conversion_rate_threshold (float): Threshold for low conversion rate.\n",
    "\n",
    "    Returns:\n",
    "    - result_dict (dict): A dictionary containing categories categorized based on thresholds.\n",
    "    \"\"\"\n",
    "    # Calculate net margin and conversion rate\n",
    "    df['net_margin'] = df['sold_items_total_cogs(euro)'] / df['sale_price_without_discount(euros)']\n",
    "    df['conversion_rate'] = df['SKUs_sold'] / df['SKUs_listed[Unique]']\n",
    "\n",
    "    # Group by category_level_0 and identify categories with high net margin and high conversion rate\n",
    "    grouped_data = df.groupby('category_level_1').agg({\n",
    "        'net_margin': 'mean',\n",
    "        'conversion_rate': 'mean'\n",
    "    })\n",
    "\n",
    "    # Reset the index to avoid the KeyError\n",
    "    grouped_data.reset_index(inplace=True)\n",
    "\n",
    "    # Categorize categories based on thresholds\n",
    "    high_net_high_conversion = grouped_data[(grouped_data['net_margin'] > high_net_margin_threshold) &\n",
    "                                            (grouped_data['conversion_rate'] > high_conversion_rate_threshold)]\n",
    "\n",
    "    high_net_low_conversion = grouped_data[(grouped_data['net_margin'] > high_net_margin_threshold) &\n",
    "                                           (grouped_data['conversion_rate'] < low_conversion_rate_threshold)]\n",
    "\n",
    "    low_net_high_conversion = grouped_data[(grouped_data['net_margin'] < low_net_margin_threshold) &\n",
    "                                           (grouped_data['conversion_rate'] > high_conversion_rate_threshold)]\n",
    "\n",
    "    low_net_low_conversion = grouped_data[(grouped_data['net_margin'] < low_net_margin_threshold) &\n",
    "                                          (grouped_data['conversion_rate'] < low_conversion_rate_threshold)]\n",
    "\n",
    "    # Prepare the result dictionary\n",
    "    result_dict = {\n",
    "        'high_net_high_conversion': high_net_high_conversion['category_level_1'].unique(),\n",
    "        'high_net_low_conversion': high_net_low_conversion['category_level_1'].unique(),\n",
    "        'low_net_high_conversion': low_net_high_conversion['category_level_1'].unique(),\n",
    "        'low_net_low_conversion': low_net_low_conversion['category_level_1'].unique()\n",
    "    }\n",
    "\n",
    "    return result_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ac2ce44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sales_vs_discounts(df):\n",
    "    \"\"\"\n",
    "    Plots a scatter plot of sales vs. discounts with a regression line using Plotly Express.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The input DataFrame containing the necessary columns.\n",
    "\n",
    "    Returns:\n",
    "    - None: Displays the interactive plot.\n",
    "    \"\"\"\n",
    "    # Scatter plot with regression line\n",
    "    fig = px.scatter(df,\n",
    "                     x='SKUs_sold',\n",
    "                     y='user_discounts(euros)',\n",
    "                     color='category_level_2',\n",
    "                     size='sale_price_without_discount(euros)',\n",
    "                     hover_name='category_level_2',\n",
    "                     labels={'SKUs_sold': 'Number of SKUs Sold', 'user_discounts(euros)': 'User Discounts (EUR)'},\n",
    "                     title='Sales vs. Discounts Scatter Plot with Regression Line',\n",
    "                     template='plotly_dark',\n",
    "                     trendline='ols')\n",
    "\n",
    "    # Update marker style\n",
    "    fig.update_traces(marker=dict(line=dict(width=0.5, color='DarkSlateGray')),\n",
    "                      selector=dict(mode='markers'))\n",
    "\n",
    "    # Add gridlines for better readability\n",
    "    fig.update_layout(xaxis=dict(showgrid=True, gridwidth=1, gridcolor='LightGray'),\n",
    "                      yaxis=dict(showgrid=True, gridwidth=1, gridcolor='LightGray'))\n",
    "\n",
    "    # Update marker color to green shades\n",
    "    green_colorscale = px.colors.sequential.Greens\n",
    "    fig.update_traces(marker=dict(color=df['user_discounts(euros)'],\n",
    "                                  colorscale=green_colorscale),\n",
    "                      selector=dict(mode='markers'))\n",
    "\n",
    "    # Show the interactive plot\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2425b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_bifurcation_on_discount_sensitivity(df):\n",
    "    \"\"\"\n",
    "    Plots a scatter plot of sales vs. discounts with a regression line for each category,\n",
    "    categorizing categories based on the slope of the regression line.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The input DataFrame containing the necessary columns.\n",
    "\n",
    "    Returns:\n",
    "    - None: Displays the interactive plot.\n",
    "    \"\"\"\n",
    "    # Scatter plot with regression line\n",
    "    fig = px.scatter(df,\n",
    "                     x='SKUs_sold',\n",
    "                     y='user_discounts(euros)',\n",
    "                     color='category_level_2',\n",
    "                     size='sale_price_without_discount(euros)',\n",
    "                     hover_name='category_level_2',\n",
    "                     labels={'SKUs_sold': 'Number of SKUs Sold', 'user_discounts(euros)': 'User Discounts (EUR)'},\n",
    "                     title='Sales vs. Discounts Scatter Plot with Regression Line',\n",
    "                     template='plotly_dark')\n",
    "\n",
    "    # Calculate the slope of the regression line for each category\n",
    "    slopes = []\n",
    "\n",
    "    for category in df['category_level_2'].unique():\n",
    "        category_data = df[df['category_level_2'] == category]\n",
    "        results = sm.OLS(category_data['user_discounts(euros)'],\n",
    "                         sm.add_constant(category_data['SKUs_sold'])).fit()\n",
    "        slope = results.params['SKUs_sold']\n",
    "        slopes.append({'category_level_2': category, 'slope': slope})\n",
    "\n",
    "    # Convert slopes to a DataFrame\n",
    "    slopes_df = pd.DataFrame(slopes)\n",
    "\n",
    "    # Define a threshold to determine if discounting matters\n",
    "    slope_threshold = 0.5\n",
    "\n",
    "    # Categorize based on the slope\n",
    "    categories_matter = slopes_df[slopes_df['slope'] >= slope_threshold]['category_level_2'].values\n",
    "    categories_do_not_matter = slopes_df[slopes_df['slope'] < slope_threshold]['category_level_2'].values\n",
    "\n",
    "    # Print the results\n",
    "    print(\"Categories where discounting matters:\")\n",
    "    print(categories_matter)\n",
    "\n",
    "    print(\"\\nCategories where discounting doesn't matter:\")\n",
    "    print(categories_do_not_matter)\n",
    "\n",
    "    # Update marker style\n",
    "    #fig.update_traces(marker=dict(line=dict(width=0.5, color='DarkSlateGray')),\n",
    "    #                  selector=dict(mode='markers'))\n",
    "\n",
    "    # Add gridlines for better readability\n",
    "    #fig.update_layout(xaxis=dict(showgrid=True, gridwidth=1, gridcolor='LightGray'),\n",
    "    #                  yaxis=dict(showgrid=True, gridwidth=1, gridcolor='LightGray'))\n",
    "\n",
    "    # Show the interactive plot\n",
    "    #fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e07981b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_waste_trends(df):\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df = df.sort_values(by='date')\n",
    "\n",
    "    # Create a categorical column for month, weekday, and date with the correct sequence\n",
    "    month_order = ['Apr', 'May', 'Jun']\n",
    "    weekday_order = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "\n",
    "    df['month'] = pd.Categorical(df['month'], categories=month_order, ordered=True)\n",
    "    df['weekday'] = pd.Categorical(df['weekday'], categories=weekday_order, ordered=True)\n",
    "    df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "\n",
    "    # Group by month, weekday, and date and sum up the values\n",
    "    df_monthly = df.groupby('month').sum().reset_index()\n",
    "    df_weekly = df.groupby('weekday').sum().reset_index()\n",
    "    df_daily = df.groupby('date').sum().reset_index()\n",
    "\n",
    "    # Create a trend graph using plotly express\n",
    "    fig_monthly = px.line(df_monthly, x='month', y='items_wasted', title='Monthly Trend - Items Wasted',\n",
    "                          labels={'items_wasted': 'Total Items Wasted', 'month': 'Month'},\n",
    "                          line_shape='linear', color_discrete_sequence=px.colors.sequential.Greens_r)\n",
    "    fig_weekly = px.line(df_weekly, x='weekday', y='items_wasted', title='Weekday Trend - Items Wasted',\n",
    "                         labels={'items_wasted': 'Total Items Wasted', 'weekday': 'Weekday'},\n",
    "                         line_shape='linear', color_discrete_sequence=px.colors.sequential.Greens_r)\n",
    "    fig_daily = px.line(df_daily, x='date', y='items_wasted', title='Date-wise Trend - Items Wasted',\n",
    "                        labels={'items_wasted': 'Total Items Wasted', 'date': 'Date'},\n",
    "                        line_shape='linear', color_discrete_sequence=px.colors.sequential.Greens_r)\n",
    "\n",
    "    # Update y-axis formatting for better readability\n",
    "    fig_monthly.update_layout(yaxis=dict(tickformat=',.2f'))\n",
    "    fig_weekly.update_layout(yaxis=dict(tickformat=',.2f'))\n",
    "    fig_daily.update_layout(yaxis=dict(tickformat=',.2f'))\n",
    "\n",
    "    # Show hover information\n",
    "    fig_monthly.update_traces(mode='lines+markers', hovertemplate='%{x}<br>%{y:,.2f}')\n",
    "    fig_weekly.update_traces(mode='lines+markers', hovertemplate='%{x}<br>%{y:,.2f}')\n",
    "    fig_daily.update_traces(mode='lines+markers', hovertemplate='%{x}<br>%{y:,.2f}')\n",
    "\n",
    "    # Show the interactive plots\n",
    "    fig_monthly.show()\n",
    "    fig_weekly.show()\n",
    "    fig_daily.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
